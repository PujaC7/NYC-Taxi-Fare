# -*- coding: utf-8 -*-
"""ML project_NYC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cKwhk8UdayigYoISJeU_dzUclUsafObN

## Install Packages
"""

pip install opendatasets

pip install pandas

"""# Load Modules"""

import opendatasets as od
import pandas

od.download("https://www.kaggle.com/competitions/new-york-city-taxi-fare-prediction")

import csv

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
plt.style.use('seaborn-whitegrid')

file = (r'New-York-City-Taxi-Fare-Prediction/\New-York-City-Taxi-Fare-Prediction.CSV')

"""# Import Libraries

"""

import pandas as pd
import numpy as np
import datetime as dt
import matplotlib.pyplot as plt
import seaborn as sb

from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold

import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor

"""# Load Data"""

import pandas as pd
import random
p = 0.01  # 1% of the lines
# keep the header, then take only 1% of lines
# if random from [0,1] interval is greater than 0.01 the row will be skipped
df = pd.read_csv('/content/new-york-city-taxi-fare-prediction/train.csv',
         header=0,
         skiprows=lambda i: i>0 and random.random() > p
)
df_test = pd.read_csv('/content/new-york-city-taxi-fare-prediction/test.csv',
         header=0,
         skiprows=lambda i: i>0 and random.random() > p)

df.head()

"""# Data Wrangling

"""

df.shape

df.info()

df.describe()

""" Checking for Missing Values"""

df.isnull().sum()

df_test.isnull().sum()

df.nunique()

"""Checking for duplicates"""

df.duplicated().sum()

"""Data preprocessing"""

df.dropna(axis=0, inplace=True)
np.sum(pd.isnull(df))

# Setting minimum fare amount to zero.
df['fare_amount'][df['fare_amount']<0] = 0.1
df[df['fare_amount']<0]

"""# Feature Engineering

Feature PreprocessingÂ¶
"""

df['pickup_datetime'] = pd.to_datetime(df.pickup_datetime)
df_test['pickup_datetime'] = pd.to_datetime(df_test.pickup_datetime)

"""Feature Generation"""

df.loc[:, 'pickup_hour'] = df['pickup_datetime'].dt.hour
df.loc[:, 'pickup_weekday'] = df['pickup_datetime'].dt.day_name()
df.loc[:, 'pickup_date'] = df['pickup_datetime'].dt.day
df.loc[:, 'pickup_month'] = df['pickup_datetime'].dt.month
df.loc[:, 'pickup_day'] = df['pickup_datetime'].dt.dayofweek
df_test.loc[:, 'pickup_hour'] = df_test['pickup_datetime'].dt.hour
df_test.loc[:, 'pickup_weekday'] = df_test['pickup_datetime'].dt.day_name()
df_test.loc[:, 'pickup_date'] = df_test['pickup_datetime'].dt.day
df_test.loc[:, 'pickup_month'] = df_test['pickup_datetime'].dt.month
df_test.loc[:, 'pickup_day'] = df_test['pickup_datetime'].dt.dayofweek

"""Base Fare"""

def baseFare(x):
    if x in range(16,20):
        base_fare = 3.50
    elif x in range(20,24):
        base_fare = 3
    else:
        base_fare = 2.50
    return base_fare

df['base_fare'] = df['pickup_hour'].apply(baseFare)
df_test['base_fare'] = df_test['pickup_hour'].apply(baseFare)
df['base_fare'], df['pickup_hour']

df['fare'] = df['fare_amount'] - df['base_fare']

"""Haversine Distance"""

from geopy.distance import great_circle
coordA=(df['pickup_latitude'][0], df['pickup_longitude'][0])
coordB=(df['dropoff_latitude'][0], df['dropoff_longitude'][0])
print (int(great_circle(coordA, coordB).kilometers))

#Method 1: haversineDistanceInKM
from math import radians, cos, sin, asin, sqrt
def haversineDistanceInKM(latA, lonA, latB, lonB):
    lonA, latA, lonB, latB = map(radians, [lonA, latA, lonB, latB])
    return int(12734 * asin(sqrt(
      sin((latB-latA)/2)**2+cos(latA)*cos(latB)*sin((lonB-lonA)/2)**2)))


latA = df['pickup_latitude'][0]
lonA = df['pickup_longitude'][0]
# Yankee stadium homeplate
latB = df['dropoff_latitude'][0]
lonB = df['dropoff_longitude'][0]
print(haversineDistanceInKM(latA, lonA, latB, lonB))

#Method 2: haversine_distance
def haversine_distance(lat1, lng1, lat2, lng2):
    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))
    AVG_EARTH_RADIUS = 6371  # in km
    lat = lat2 - lat1
    lng = lng2 - lng1
    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2
    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))
    return h

df['haversine_distance'] = haversine_distance(df['pickup_latitude'].values,
                                                     df['pickup_longitude'].values,
                                                     df['dropoff_latitude'].values,
                                                     df['dropoff_longitude'].values)
df_test['haversine_distance'] = haversine_distance(df_test['pickup_latitude'].values,
                                                     df_test['pickup_longitude'].values,
                                                     df_test['dropoff_latitude'].values,
                                                     df_test['dropoff_longitude'].values)

df['haversine_distance'].median(), df['haversine_distance'].mean(),

df.head()

df.shape

new_df = df.iloc[:10000, :]
new_df.shape

import sklearn.neighbors
import numpy as np
dist = sklearn.neighbors.DistanceMetric.get_metric('haversine')
dist_miles = (dist.pairwise
    (np.radians(new_df[['pickup_latitude', 'pickup_longitude']]),
     np.radians(new_df[['dropoff_latitude','dropoff_longitude']]))*3959)
# Note that 3959 is the radius of the earth in miles
dist_km = (dist.pairwise
    (np.radians(new_df[['pickup_latitude', 'pickup_longitude']]),
     np.radians(new_df[['dropoff_latitude','dropoff_longitude']]))*6371)
df_dist_km = pd.DataFrame(dist_km)
df_dist_km.head()

from sklearn.metrics.pairwise import haversine_distances
pickup_in_radians = np.radians(new_df[['pickup_latitude', 'pickup_longitude']])
dropoff_in_radians = np.radians(new_df[['dropoff_latitude','dropoff_longitude']])
result = pd.DataFrame(haversine_distances(pickup_in_radians, dropoff_in_radians)*6371)
result.head()

mydiagonal = np.matrix.diagonal(np.array(result))
distance = pd.DataFrame(mydiagonal, index = new_df.index, columns = ['distance'])
distance.head()

"""# Exploratory Data Analysis (EDA)"""

plt.figure(figsize=(22, 6))
#fig, axs = plt.subplot(ncols=2)

# Passenger Count
plt.subplot(121)
sb.countplot(x=new_df['passenger_count'])
plt.xlabel('Passenger Count')
plt.ylabel('Frequency')
plt.title('Frequency Distribution of Passenger Count')

plt.subplot(122)
sb.boxplot(x=new_df['passenger_count'], color = 'cyan', showmeans=True,
           meanprops={"marker":"o", "markerfacecolor":"Red",
                      "markeredgecolor":"black","markersize":"10"}
)
plt.xlabel('Passenger Count')
plt.title('Box plot of Passenger count');

new_df['pickup_date'].value_counts()

# Datetime features
plt.figure(figsize=(18
                    , 9))

# Hour of day
plt.subplot(221)
sb.countplot(x=new_df['pickup_hour'])
plt.xlabel('Hour of Day')
plt.ylabel('Total number of pickups')
plt.title('Hourly Variation of Total number of pickups')

# Date
plt.subplot(223)
sb.countplot(x=new_df['pickup_date'])
plt.xlabel('Date')
plt.ylabel('Total number of pickups')
plt.title('Daily Variation of Total number of pickups')

# Day of week
plt.subplot(222)
sb.countplot(x=new_df['pickup_weekday'], order = ['Monday', 'Tuesday', 'Wednesday','Thursday', 'Friday', 'Saturday', 'Sunday'])
plt.xlabel('Week Day')
plt.ylabel('Total Number of pickups')
plt.title('Weekly Variation of Total number of pickups')

# Month
plt.subplot(224)
sb.countplot(x=
             new_df['pickup_month'])
plt.xlabel('Month')
plt.ylabel('Total number of pickups')
plt.tight_layout()
plt.title('Monthly Variation of Total number of pickups');

plt.figure(figsize=(22, 6))
sb.boxplot(x = new_df['passenger_count'],y = new_df['fare_amount'], color = 'cyan', showmeans=True,
            meanprops={"marker":"o", "markerfacecolor":"Red", "markeredgecolor":"black","markersize":"10"}
)
plt.xlabel('Passenger Count')
plt.title ("Fare amount vs No. of passengers");

plt.figure(figsize=(15, 6))
sb.boxplot(x = new_df['pickup_weekday'], order = ['Monday', 'Tuesday', 'Wednesday',
                                           'Thursday', 'Friday', 'Saturday', 'Sunday'],y = new_df['passenger_count'], color = 'cyan', showmeans=True,
            meanprops={"marker":"o", "markerfacecolor":"Red", "markeredgecolor":"black","markersize":"10"}
)
plt.xlabel('Passenger Count')
plt.title ("No. of passengers vs Days of week");

# Datetime features
plt.figure(figsize=(22, 8))

# Hour of day
plt.subplot(221)
sb.barplot(x = new_df['pickup_hour'], y = new_df['passenger_count'], palette = 'hsv')
plt.xlabel('Hour of Day')
plt.ylabel('Passenger count')
plt.title ("Passenger count vs Hour of Day")

# Day of week
plt.subplot(222)
sb.barplot(x = new_df['pickup_month'], y = new_df['passenger_count'],palette = 'hsv')
plt.xlabel('Month')
plt.ylabel('Passenger count')
plt.title ("Passenger count vs Month")

# Date
plt.subplot(223)
sb.barplot(x = new_df['pickup_date'], y = new_df['passenger_count'], palette = 'hsv')
plt.xlabel('Date')
plt.ylabel('Passenger count')
plt.title ("Passenger count vs Date")

# Month
plt.subplot(224)
sb.barplot(x = new_df['pickup_weekday'], order = ['Monday', 'Tuesday', 'Wednesday',
                                           'Thursday', 'Friday', 'Saturday', 'Sunday'],
           y = new_df['passenger_count'], palette = 'hsv')
plt.xlabel('Days of week')
plt.ylabel('Passenger count')
plt.title ("Passenger count vs Days of week")
plt.tight_layout();

plt.figure(figsize=(15, 6))
sb.boxplot(x = new_df['pickup_weekday'], order = ['Monday', 'Tuesday', 'Wednesday',
                                           'Thursday', 'Friday', 'Saturday', 'Sunday'],
           y = new_df['fare_amount'], palette = 'rainbow', showmeans=True,
            meanprops={"marker":"o", "markerfacecolor":"Red", "markeredgecolor":"black",
                       "markersize":"10"}
)
plt.xlabel('Fare amount')
plt.title ("Fare amount vs Days of week");

sb.distplot(new_df['haversine_distance'], bins = 20);

new_df['haversine_distance'].describe(), print("Median       ", new_df['haversine_distance'].median())

new_df['haversine_distance'].quantile(0.25), new_df['haversine_distance'].quantile(0.75)

IQR = new_df['haversine_distance'].quantile(0.75) - new_df['haversine_distance'].quantile(0.25)
IQR

Q1 = new_df['haversine_distance'].quantile(0.25)
Q3 = new_df['haversine_distance'].quantile(0.75)
whisker_1 = Q1 - (1.5*IQR)
whisker_2 = Q3 + (1.5*IQR)

whisker_1, whisker_2

new_df = new_df.loc[(new_df['haversine_distance']!=0) & (new_df['haversine_distance']<8)]
new_df.shape

sb.distplot(new_df['haversine_distance'], bins = 20)
plt.show()

"""Target exploration with distance"""

from scipy import stats
x = new_df['haversine_distance']
y = new_df['fare_amount']
slope, intercept, r_value, p_value, std_err = stats.linregress(new_df['haversine_distance'],new_df['fare_amount'])
data = pd.concat([new_df['haversine_distance'], new_df['fare_amount']], axis=1)
ax = sb.regplot(data=data, x='haversine_distance', y='fare_amount', line_kws={'label':"y={0:.1f}x+{1:.1f}".format(slope,intercept),
                                                                    "color": "red"},scatter_kws={"color": "cyan"})
ax.legend();

#sb.lmplot(x="haversine_distance", y="fare_amount", data=df );
sb.relplot(x="haversine_distance", y="fare_amount", data=new_df, kind="scatter");

# Datetime features
plt.figure(figsize=(22, 8))

# Hour of day
plt.subplot(221)
sb.barplot(x=new_df['pickup_hour'], y = new_df['haversine_distance'], palette = 'tab20')
plt.xlabel('Hour of Day')
plt.ylabel('Distance in Km')
plt.title ("Distance in Km vs Hour of Day")

# Day of week
plt.subplot(222)
sb.barplot(x=new_df['pickup_month'], y = new_df['haversine_distance'],palette = 'tab20',estimator = np.mean)
plt.xlabel('Month')
plt.ylabel('Distance in Km')
plt.title ("Distance in Km vs Month")

# Date
plt.subplot(223)
sb.barplot(x = new_df['pickup_date'], y = new_df['haversine_distance'], palette = 'tab20')
plt.xlabel('Date')
plt.ylabel('Distance in Km')
plt.title ("Distance in Km vs Date")

# Month
plt.subplot(224)
sb.barplot(x = new_df['pickup_weekday'], order = ['Monday', 'Tuesday', 'Wednesday',
                                           'Thursday', 'Friday', 'Saturday', 'Sunday'],
           y = new_df['haversine_distance'], palette = 'tab10')
plt.xlabel('Days of week')
plt.ylabel('Distance in Km')
plt.title ("Distance in Km vs Days of week")
plt.tight_layout();

# Datetime features
plt.figure(figsize=(22, 8))

# Hour of day
plt.subplot(221)
sb.barplot(x=new_df['pickup_hour'], y = new_df['fare_amount'], palette = 'tab20')
plt.xlabel('Hour of Day')
plt.ylabel('Fare amount')
plt.title ("Fare amount vs Hour of Day")

# Day of week
plt.subplot(222)
sb.barplot(x=new_df['pickup_month'], y = new_df['fare_amount'],palette = 'tab20')
plt.xlabel('Month')
plt.ylabel('Fare amount')
plt.title ("Fare amount vs Month")

# Date
plt.subplot(223)
sb.barplot(x = new_df['pickup_date'], y = new_df['fare_amount'], palette = 'tab20')
plt.xlabel('Date')
plt.ylabel('Fare amount')
plt.title ("Fare amount vs Date")

# Month
plt.subplot(224)
sb.barplot(x = new_df['pickup_weekday'], order = ['Monday', 'Tuesday', 'Wednesday',
                                           'Thursday', 'Friday', 'Saturday', 'Sunday'],
           y = new_df['fare_amount'], palette = 'tab10')
plt.xlabel('Days of week')
plt.ylabel('Fare amount')
plt.title ("Fare amount vs Days of week")
plt.tight_layout();

f, axes = plt.subplots(2,2,figsize=(10, 10), sharex=False, sharey = False)
sb.despine(left=True)
sb.distplot(new_df['pickup_latitude'].values, label = 'pickup_latitude',color="b",bins = 100, ax=axes[0,0])
sb.distplot(new_df['pickup_longitude'].values, label = 'pickup_longitude',color="r",bins =100, ax=axes[1,0])
sb.distplot(new_df['dropoff_latitude'].values, label = 'dropoff_latitude',color="b",bins =100, ax=axes[0,1])
sb.distplot(new_df['dropoff_longitude'].values, label = 'dropoff_longitude',color="r",bins =100, ax=axes[1,1])
plt.setp(axes, yticks=[])
plt.tight_layout()
plt.show()

new_df = new_df.loc[(new_df.pickup_latitude > 40.6) & (new_df.pickup_latitude < 40.9)]
new_df = new_df.loc[(new_df.dropoff_latitude>40.6) & (new_df.dropoff_latitude < 40.9)]
new_df = new_df.loc[(new_df.dropoff_longitude > -74.05) & (new_df.dropoff_longitude < -73.7)]
new_df = new_df.loc[(new_df.pickup_longitude > -74.05) & (new_df.pickup_longitude < -73.7)]
new_df_data_new = new_df.copy()
sb.set(style="white", palette="muted", color_codes=True)
f, axes = plt.subplots(2,2,figsize=(10, 10), sharex=False, sharey = False)#
sb.despine(left=True)
sb.distplot(new_df_data_new['pickup_latitude'].values, label = 'pickup_latitude',color="b",bins = 100, ax=axes[0,0])
sb.distplot(new_df_data_new['pickup_longitude'].values, label = 'pickup_longitude',color="r",bins =100, ax=axes[0,1])
sb.distplot(new_df_data_new['dropoff_latitude'].values, label = 'dropoff_latitude',color="b",bins =100, ax=axes[1, 0])
sb.distplot(new_df_data_new['dropoff_longitude'].values, label = 'dropoff_longitude',color="r",bins =100, ax=axes[1, 1])
plt.setp(axes, yticks=[])
plt.tight_layout()

plt.show()

"""Distribution plot of target variable"""

import holoviews as hv
from holoviews import opts
hv.extension('bokeh')
hv.Distribution(new_df['fare_amount']).opts(title="Fare Amount Distribution", color="red",
                                                        xlabel="Fare Amount", ylabel="Density")\
.opts(opts.Distribution(width=700, height=300,tools=['hover'],show_grid=True))

from patsy import dmatrices
from statsmodels.stats.outliers_influence import variance_inflation_factor
# the independent variables set
X =new_df.drop(['key', 'pickup_datetime','pickup_weekday', 'fare_amount', 'base_fare', 'fare'], axis = 1)

# VIF dataframe
vif_data = pd.DataFrame()
vif_data["feature"] = X.columns

# calculating VIF for each feature
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

print(vif_data)

"""Correlation matrix"""

plt.figure(figsize = (12,6))
sb.heatmap(df.drop(['key', 'pickup_datetime','pickup_weekday'], axis = 1).corr(),
           cmap ='BuGn', annot = True);

new_df[['pickup_latitude', 'pickup_longitude', 'dropoff_longitude', 'dropoff_latitude']].corr()

"""Data scaling and Train Test split"""

new_df.info()

X = new_df.drop(['key', 'pickup_datetime','pickup_weekday', 'fare_amount', 'fare', 'base_fare', 'dropoff_latitude', 'dropoff_longitude'],
            axis = 1)
y = new_df['fare_amount']

from sklearn import preprocessing
X= preprocessing.StandardScaler().fit(X).transform(X)
X[0:5]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
print(X_train.ndim)
print(y_train.ndim)
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

"""Mean prediction"""

from sklearn.metrics import mean_squared_error
from math import sqrt
mean_pred = np.repeat(y_train.mean(),len(y_test))
sqrt(mean_squared_error(y_test, mean_pred))

"""# Model Development"""

pip install -q --upgrade linear-tree

"""Cross Validation(CV)

###Linear Regression
"""

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
np.mean(cross_val_score(lr, X_train, y_train, cv=5))

from sklearn.model_selection import cross_validate
cv_results = cross_validate(lr, X_train, y_train, cv=5, return_estimator=True)

Coefficient = []
for model in cv_results['estimator']:
    Coefficient.append(model.coef_)
new_df_train = new_df.drop(['key', 'pickup_datetime','pickup_weekday', 'fare_amount', 'fare', 'base_fare',
                    'dropoff_latitude', 'dropoff_longitude'], axis = 1)
coefficient = pd.DataFrame(Coefficient, columns = new_df_train.columns)
abs(coefficient.mean(axis =0)).sort_values(ascending = False)

"""###Ridge Regression"""

from sklearn.linear_model import RidgeCV
ridge = RidgeCV(cv=5).fit(X_train, y_train)
ridge.score(X_train, y_train)

from sklearn.model_selection import cross_validate
cv_results = cross_validate(ridge, X_train, y_train, cv=5, return_estimator=True)

Coefficient = []
for model in cv_results['estimator']:
    Coefficient.append(model.coef_)

coefficient = pd.DataFrame(Coefficient, columns = new_df_train.columns)
abs(coefficient.mean(axis =0)).sort_values(ascending = False)

"""###Lasso Regression"""

from sklearn.linear_model import LassoCV
lasso = LassoCV(cv=5).fit(X_train, y_train)
lasso.score(X_train, y_train)

from sklearn.model_selection import cross_validate
cv_results = cross_validate(lasso, X_train, y_train, cv=5, return_estimator=True)

Coefficient = []
for model in cv_results['estimator']:
    Coefficient.append(model.coef_)
coefficient = pd.DataFrame(Coefficient, columns = new_df_train.columns)
abs(coefficient.mean(axis =0)).sort_values(ascending = False)

"""###Elasticnet Regression"""

from sklearn.linear_model import ElasticNetCV
elastic = ElasticNetCV(cv=5).fit(X_train, y_train)
elastic.score(X_train, y_train)

from sklearn.model_selection import cross_validate
cv_results = cross_validate(elastic, X_train, y_train, cv=5, return_estimator=True)

Coefficient = []
for model in cv_results['estimator']:
    Coefficient.append(model.coef_)
coefficient = pd.DataFrame(Coefficient, columns = new_df_train.columns)
abs(coefficient.mean(axis =0)).sort_values(ascending = False)

"""###Polynomial Regression


"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
cv_score=[]
for i in range(1,4):
    poly_reg = PolynomialFeatures(degree = i)
    X_poly = poly_reg.fit_transform(X_train)
    poly_reg = LinearRegression()
    cv_score.append(np.mean(cross_val_score(poly_reg,X_poly,y_train,cv=5)))
x = range(1,4)
plt.scatter(x,cv_score)
plt.xticks(ticks=[1,2,3], labels=['Degree_1', 'Degree_2', 'Degree_3']);

from sklearn.model_selection import cross_validate
cv_results = cross_validate(poly_reg, X_train, y_train, cv=5, return_estimator=True)

Coefficient = []
for model in cv_results['estimator']:
    Coefficient.append(model.coef_)
coefficient = pd.DataFrame(Coefficient, columns = new_df_train.columns)
abs(coefficient.mean(axis =0)).sort_values(ascending = False)

"""###K-Nearest Neighbor (KNN)"""

from sklearn.neighbors import KNeighborsRegressor
cv_score=[]
for i in range(1,10):
 knn = KNeighborsRegressor(n_neighbors= i)
 cv_score.append(np.mean(cross_val_score(knn,X_train, y_train,cv=5)))
x = range(1,10)
plt.scatter(x,cv_score);

"""###Decision Tree"""

from sklearn.tree import DecisionTreeRegressor
DT = DecisionTreeRegressor()
R_Squared = np.mean(cross_val_score(DT, X_train, y_train, cv=5))
Standard_deviation = np.std(cross_val_score(DT, X_train, y_train, cv=5))
print('R2 of Decision Tree Regression model is:',R_Squared)
print('Standard deviation of R2 of Decision Tree Regression model is:',Standard_deviation)

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
R_Squared = np.mean(cross_val_score(rf, X_train, y_train, cv=5))
Standard_deviation = np.std(cross_val_score(rf, X_train, y_train, cv=5))
print('R2 of Random Forest Regression model is:',R_Squared)
print('Standard deviation of R2 of Random Forest Regression model is:',Standard_deviation)

"""###Gradient boosting Regression"""

from sklearn.ensemble import GradientBoostingRegressor
GB = GradientBoostingRegressor()
np.mean(cross_val_score(GB, X_train, y_train, cv=5))

new_df['haversine_distance_log'] = np.log(new_df['haversine_distance'].values + 1)
new_df['haversine_distance_sqrt'] = np.sqrt(new_df['haversine_distance'].values)
new_df['haversine_distance_sq'] = new_df['haversine_distance'].values**2
new_df['haversine_distance_log'] = np.log(new_df['haversine_distance'].values + 1)
new_df['haversine_distance_sqrt'] = np.sqrt(new_df['haversine_distance'].values)
f, axes = plt.subplots(2,2,figsize=(10, 10), sharex=False, sharey = False)#
sb.despine(left=True)
sb.distplot(new_df['haversine_distance'], label = 'haversine_distance',color="b",bins = 100, ax=axes[0,0])
axes[0,0].set_title('Histogram of distance')
sb.distplot(new_df['haversine_distance_log'], label = 'haversine_distance_log',color="yellow",bins =100, ax=axes[0,1])
axes[0,1].set_title('Histogram of log of distance')
sb.distplot(new_df['haversine_distance_sqrt'], label = 'haversine_distance_sqrt',color="magenta",bins =100, ax=axes[1, 0])
axes[1,0].set_title('Histogram of sqrt of distance')
sb.distplot(new_df['haversine_distance_sq'], label = 'haversine_distance_sq',color="green",bins =100, ax=axes[1, 1])
axes[1,1].set_title('Histogram of square of distance')
plt.setp(axes, yticks=[])
plt.tight_layout()

plt.show()

new_df_train = new_df.drop(['key', 'pickup_datetime','pickup_weekday', 'fare', 'fare_amount', 'base_fare',
                    'haversine_distance', 'haversine_distance_sq', 'haversine_distance_sqrt'], axis = 1)
new_df_test_copy = new_df.drop(['key', 'base_fare', 'pickup_datetime','pickup_weekday', 'base_fare','haversine_distance',
                             'haversine_distance_sqrt'], axis = 1)
#new_df_test_copy = new_df_test.drop(['key', 'base_fare', 'pickup_datetime','pickup_weekday', 'base_fare','haversine_distance', 'haversine_distance_sqrt','pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude' ], axis = 1)
X = new_df_train.copy()
y = new_df['fare_amount']
new_df_train.columns, new_df_test_copy.columns

scaler = preprocessing.StandardScaler()
X= scaler.fit(X).transform(X)
#test_X= scaler.transform(new_df_test_copy)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
from sklearn.model_selection import cross_validate
cv_results = cross_validate(ridge, X_train, y_train, cv=5, return_estimator=True)

Coefficient = []
for model in cv_results['estimator']:
    Coefficient.append(model.coef_)

coefficient = pd.DataFrame(Coefficient, columns = new_df_train.columns)
abs(coefficient.mean(axis =0)).sort_values(ascending = False)

from sklearn.linear_model import RidgeCV
ridge = RidgeCV(cv=5).fit(X_train, y_train)
ridge.score(X_train, y_train)

new_df.head()

"""# Model Evaluation & Kaggle Submission"""

def model_train_evaluation(y, ypred, model_name):

    # Model Evaluation metrics
    from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score, r2_score, mean_absolute_percentage_error
    print("\n \n Model Evaluation Report: ")
    print('Mean Absolute Error(MAE) of', model_name,':', mean_absolute_error(y, ypred))
    print('Mean Squared Error(MSE) of', model_name,':', mean_squared_error(y, ypred))
    print('Root Mean Squared Error (RMSE) of', model_name,':', mean_squared_error(y, ypred, squared = False))
    print('Mean absolute percentage error (MAPE) of', model_name,':', mean_absolute_percentage_error(y, ypred))
    print('Explained Variance Score (EVS) of', model_name,':', explained_variance_score(y, ypred))
    print('R2 of', model_name,':', (r2_score(y, ypred)).round(2))
    print('\n \n')

    # Actual vs Predicted Plot
    f, ax = plt.subplots(figsize=(12,6),dpi=100);
    plt.scatter(y, ypred, label="Actual vs Predicted")
    # Perfect predictions
    plt.xlabel('Fare amount')
    plt.ylabel('Fare amount')
    plt.title('Expection vs Prediction')
    plt.plot(y,y,'r', label="Perfect Expected Prediction")
    plt.legend()
    f.text(0.95, 0.06, 'AUTHOR: RINI CHRISTY',
         fontsize=12, color='green',
         ha='left', va='bottom', alpha=0.5);
    plt.show()

"""###Linear regression evaluation"""

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit (X_train, y_train)
Yhat_lr = lr.predict(X_test)
model_train_evaluation(y_test, Yhat_lr, 'Linear regression Model')

test_pred = lr.predict(X_test)
Submission = pd.DataFrame(test_pred, columns = ['fare_amount'])
Submission['key'] = new_df['key']
Submission = Submission[['key', 'fare_amount']]
Submission.head()

!pip3 list